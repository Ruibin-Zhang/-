{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from more_itertools import locate\n",
    "import os\n",
    "\n",
    "import json\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取当前目录路径\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# 定义子目录名\n",
    "subdir_name = 'Output_treads'\n",
    "# subdir_name1 = 'Output_pelicun'\n",
    "# subdir_name2 = 'Output_preprocessing'\n",
    "\n",
    "# 创建子目录\n",
    "subdir_path = os.path.join(current_dir, subdir_name)\n",
    "# subdir_pelicun = os.path.join(current_dir, subdir_name1)\n",
    "# subdir_preprocessing = os.path.join(current_dir, subdir_name2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建pickle文件的完整路径 导入RC_results\n",
    "# pickle_file_path = os.path.join(subdir_treads, 'RC_results.pkl')\n",
    "pickle_file_path = 'Output_treads/RC_results.pkl'\n",
    "\n",
    "# 从pickle文件中加载字典数据\n",
    "with open(pickle_file_path, \"rb\") as file:\n",
    "    RC_results = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RCtable_input = 'Repair_Class_Table_R.csv'\n",
    "DMG_input = 'Output_preprocessing/DMG_sample_R.csv' #pelicun output 经过前处理，去掉了倒塌和不可修复的情况，和无损伤的样本\n",
    "DV_rec_time_input = 'Output_preprocessing/loss_sample_time_DMG.csv'\n",
    "input_params_json = 'Output_preprocessing/input_parameters_R.json'\n",
    "DL_summary_input = 'Output_pelicun/DL_summary.csv' #pelicun output\n",
    "\n",
    "RC = RC_results[\"RC\"]\n",
    "RCmax_RS = np.squeeze(RC_results[\"RCmax_RS\"])\n",
    "\n",
    "output_path = subdir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_params_json) as f:\n",
    "    input_param = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sum(input_param['repair_phases'])!=len(RCmax_RS.T)/7:  #7为维修顺序数量（RS1-RS7）\n",
    "    sys.exit(\"Sum of repair phases is not equal to the number of stories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repair time calculation\n",
    "n_elev = input_param['elevator_quantity']\n",
    "rep_phases = input_param['repair_phases']\n",
    "fl_area = input_param['floor_area']\n",
    "max_num_workers = input_param['max_number_workers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RC_table = pd.read_csv(RCtable_input) \n",
    "DMG = pd.read_csv(DMG_input, low_memory=False, header=None)\n",
    "\n",
    "DV_rec_time = pd.read_csv(DV_rec_time_input, low_memory=False, header=None)\n",
    "rec_time = DV_rec_time.loc[4:,0:]\n",
    "DMG_all = DMG.loc[4:, 1:]\n",
    "RC_data = RC.iloc[4:,1:]\n",
    "FG_all = RC_table[\"Fragility\"]\n",
    "Qty_FEMA = RC_table['Qty unit FEMA P-58']\n",
    "Wrk_DMG = RC_table['Workers per damaged Qty']\n",
    "\n",
    "\n",
    "FG = DMG.loc[0, 1:] #fragility groups \n",
    "n_PG = len(FG)  #number of performance groups 不同EDP，不同方向，不同楼层\n",
    "DL_summary=pd.read_csv(DL_summary_input)\n",
    "\n",
    "#determine indices for collpase, irreparable, and repairable realizations\n",
    "cases_collapse = DL_summary[\"collapses/collapsed\"]\n",
    "indx_collapse = cases_collapse[cases_collapse==1].index\n",
    "cases_irreparable = DL_summary[\"reconstruction/irreparable\"]\n",
    "indx_irreparable = cases_irreparable[cases_irreparable==1].index\n",
    "indx_all = DL_summary[\"#Num\"]\n",
    "indx_repairable =  indx_all.drop(indx_collapse.union(indx_irreparable))\n",
    "\n",
    "for i in range(len(DMG_all)):\n",
    "    if int(DMG.loc[i+4, 0]) in indx_irreparable:            \n",
    "        DMG_all.iloc[i,:]=np.nan\n",
    "DMG_repairable = DMG_all.dropna()\n",
    "DMG_repairable = DMG_repairable.astype('float')\n",
    "DMG_repairable = np.array(DMG_repairable)\n",
    "\n",
    "RT_RC2 = np.zeros((len(indx_repairable),n_PG))  #repair times for functional recovery \n",
    "DMG_RC2 = np.zeros((len(indx_repairable),n_PG))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RT_RC2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the number of damaged components and repair times for each recovery state\n",
    "for i in range(len(indx_repairable)):\n",
    "    for j in range(n_PG):\n",
    "        if DMG_repairable[i,j] != 0 and float(RC_data.iloc[i,j]) >= 2:\n",
    "            RT_RC2[i,j] = float(rec_time.iloc[i,j])\n",
    "            DMG_RC2[i,j] = DMG_repairable[i,j]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create matrix of FEMA P-58 coefficients for fragilities\n",
    "Qty_norm=[]\n",
    "Wrk_norm=[]\n",
    "for i in range(n_PG):\n",
    "    indx_FG = FG_all[FG_all==FG[i+1]].index\n",
    "    Qty_norm.append(Qty_FEMA[indx_FG])\n",
    "    Wrk_norm.append(Wrk_DMG[indx_FG])\n",
    "Qty_norm = np.stack( Qty_norm, axis=0)\n",
    "Wrk_norm = np.stack( Wrk_norm, axis=0)\n",
    "Qty_norm_mat = np.repeat(Qty_norm.T, len(indx_repairable), axis=0)\n",
    "Wrk_norm_mat = np.repeat(Wrk_norm.T, len(indx_repairable), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of damaged components matrix for each recovery state\n",
    "N_DMG_RC2 = np.ceil(np.divide(DMG_RC2,Qty_norm_mat)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DMG_RC2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edit the number of damaged FEMA P-58 elevator components (simultaneous damage states)\n",
    "PG = DMG.loc[1, 1:]\n",
    "story_FG = []\n",
    "for i in range(n_PG):\n",
    "    story_FG.append(int((PG[i+1])))\n",
    "\n",
    "story = list(set(story_FG))\n",
    "story.sort()\n",
    "\n",
    "indx_PG1 = (PG[PG=='1'].index)-1\n",
    "indx_FG1 = (FG[FG=='D.10.14.011'].index)-1 #易损性组只有构件类型有关\n",
    "indx = indx_PG1.intersection(indx_FG1)\n",
    "for k in range(len(indx_repairable)):\n",
    "    maxx = np.max(N_DMG_RC2[k][indx], initial=0.0001)\n",
    "    a = N_DMG_RC2[k][indx]\n",
    "    a[a<maxx]=0\n",
    "    N_DMG_RC2[k][indx] = (a*n_elev[0])/np.max([n_elev[0],np.sum(a)]) #电梯损伤单元个数\n",
    "    \n",
    "\n",
    "indx_PG1 = (PG[PG=='30'].index)-1\n",
    "indx_FG1 = (FG[FG=='D.10.14.011'].index)-1\n",
    "indx = indx_PG1.intersection(indx_FG1)\n",
    "for k in range(len(indx_repairable)):\n",
    "    maxx = np.max(N_DMG_RC2[k][indx], initial=0.0001)\n",
    "    a = N_DMG_RC2[k][indx]\n",
    "    a[a<maxx]=0\n",
    "    N_DMG_RC2[k][indx] = (a*n_elev[1])/np.max([n_elev[1],np.sum(a)]) #电梯损伤单元个数\n",
    "    \n",
    "# indx = (FG[FG=='D1014.012'].index)-1\n",
    "# for k in range(len(indx_repairable)):\n",
    "#     maxx = np.max(N_DMG_RC2[k][indx], initial=0.0001)\n",
    "#     a = N_DMG_RC2[k][indx]\n",
    "#     a[a<maxx]=0\n",
    "#     N_DMG_RC2[k][indx] = (a*n_elev)/np.max([n_elev,np.sum(a)])\n",
    "    \n",
    "# indx = (FG[FG=='D1014.021'].index)-1\n",
    "# for k in range(len(indx_repairable)):\n",
    "#     maxx = np.max(N_DMG_RC2[k][indx], initial=0.0001)\n",
    "#     a = N_DMG_RC2[k][indx]\n",
    "#     a[a<maxx]=0\n",
    "#     N_DMG_RC2[k][indx] = (a*n_elev)/np.max([n_elev,np.sum(a)])\n",
    "\n",
    "# indx = (FG[FG=='D1014.022'].index)-1\n",
    "# for k in range(len(indx_repairable)):\n",
    "#     maxx = np.max(N_DMG_RC2[k][indx], initial=0.0001)\n",
    "#     a = N_DMG_RC2[k][indx]\n",
    "#     a[a<maxx]=0\n",
    "#     N_DMG_RC2[k][indx] = (a*n_elev)/np.max([n_elev,np.sum(a)])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#an original matrix for number of workers is generated using the values defined in the repair class table\n",
    "N_Wrk_RC2 = (np.multiply(N_DMG_RC2,Wrk_norm_mat)) #number of workers matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% repair time calculation per sequence per story\n",
    "\n",
    "FG_all = RC_table[\"Fragility\"]\n",
    "RS_all = RC_table[\"Repair Sequence\"]\n",
    "\n",
    "RS_FG =[] #每个易损性组对应的维修顺序\n",
    "\n",
    "for i in range(n_PG):    \n",
    "    indx_FG = FG_all[FG_all==FG[i+1]].index\n",
    "    RS_FG.append(RS_all[indx_FG[0]])  #每个易损性对应的维修顺序(RS)\n",
    "\n",
    "RS = list(set(RS_FG))\n",
    "RS.sort()\n",
    "\n",
    "header=[]\n",
    "for i in range(len(story)):\n",
    "    for j in range(len(RS)):\n",
    "        header.append(str(story[i])+'_'+str(RS[j]))\n",
    "header_ = np.vstack((header, [\"\"]*len(header)))\n",
    "col = np.append('St_RSeq', np.append('#Num', np.arange(0,len(indx_repairable),1))) #按照楼层和修复顺序分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "RT_RC2_RS=[]\n",
    "N_Wrk_RC2_RS=[]\n",
    "\n",
    "for i in range(len(indx_repairable)):\n",
    "    RT_RC2_realization = RT_RC2[i,:]\n",
    "    N_Wrk_RC2_realization = N_Wrk_RC2[i,:]\n",
    "    RT_RC2_RS.append([])\n",
    "    N_Wrk_RC2_RS.append([])\n",
    "\n",
    "    for j in range(len(story)):\n",
    "        for k in range(len(RS)):\n",
    "            indx_ST = list(locate(story_FG, lambda x: x == story[j]))\n",
    "            indx_RS = list(locate(RS_FG, lambda x: x == RS[k]))\n",
    "            indx_intersect = list(set.intersection(set(indx_ST),set(indx_RS)))  #安装楼层和维修顺序分组\n",
    "            RT_RC2_RS[i].append(np.sum(RT_RC2_realization[indx_intersect]))\n",
    "            N_Wrk_RC2_RS[i].append(np.sum(N_Wrk_RC2_realization[indx_intersect]))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% worker allocation limits\n",
    "N_Wrk_RC2_RS_org = np.squeeze(N_Wrk_RC2_RS)\n",
    "N_Wrk_RC2_RS_adj = np.squeeze(N_Wrk_RC2_RS)  #调整工人数量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Wrk_RC2_RS.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_worker_fl = np.zeros((len(indx_repairable),len(story))) #工人数量限值\n",
    "for i in range(len(indx_repairable)):\n",
    "    for j in range(len(story)):\n",
    "        if (float(np.max(RC.iloc[i+4,:])) >= 4):\n",
    "            max_worker_fl[i,j] = (1/500)*fl_area[j]\n",
    "        else: max_worker_fl[i,j] = (1/1000)*fl_area[j]\n",
    "\n",
    "if (len(story) <= 5):\n",
    "    max_worker_seq = max_num_workers\n",
    "elif (len(story) > 5) and (len(story) <= 20):\n",
    "    max_worker_seq = [2 * k for k in max_num_workers]\n",
    "else:\n",
    "    max_worker_seq = [3 * k for k in max_num_workers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#worker limit per repair sequence based on the floor area\n",
    "for i in range(len(indx_repairable)):\n",
    "    for j in range(len(story)):\n",
    "        N_Wrk_RC2_RS_adj[i,j*7] = min(N_Wrk_RC2_RS_org[i,j*7], max_worker_fl[i,j])\n",
    "        \n",
    "        N_Wrk_RC2_RS_adj[i,j*7+2] = min(N_Wrk_RC2_RS_org[i,j*7+2], max_worker_fl[i,j])\n",
    "        \n",
    "        N_Wrk_RC2_RS_adj[i,j*7+5] = min(N_Wrk_RC2_RS_org[i,j*7+5], max_worker_fl[i,j])\n",
    "        \n",
    "        N_Wrk_RC2_RS_adj[i,j*7+6] = min(N_Wrk_RC2_RS_org[i,j*7+6], max_worker_fl[i,j])\n",
    "        \n",
    "        summ2 =  N_Wrk_RC2_RS_org[i,j*7+1]+N_Wrk_RC2_RS_org[i,j*7+3]+N_Wrk_RC2_RS_org[i,j*7+4]\n",
    "        \n",
    "        if (summ2 > max_worker_fl[i,j]): #修复阶段2（RS2-RS4-RS5）的工人数量超限时，按比例分配\n",
    "            N_Wrk_RC2_RS_adj[i,j*7+1] = np.round((N_Wrk_RC2_RS_org[i,j*7+1])*(max_worker_fl[i,j]/summ2))\n",
    "            N_Wrk_RC2_RS_adj[i,j*7+3] = np.round((N_Wrk_RC2_RS_org[i,j*7+3])*(max_worker_fl[i,j]/summ2))\n",
    "            N_Wrk_RC2_RS_adj[i,j*7+4] = np.round((N_Wrk_RC2_RS_org[i,j*7+4])*(max_worker_fl[i,j]/summ2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#worker limit per repair sequence based on the numbers defined in Paul et al. (2018) table 1\n",
    "N_Wrk_RC2_RS_adj2 = N_Wrk_RC2_RS_adj\n",
    "\n",
    "for i in range(len(indx_repairable)):\n",
    "    x=0\n",
    "    for j in range(len(rep_phases)):\n",
    "        for k in range(len(RS)):\n",
    "            summ = sum(N_Wrk_RC2_RS_adj[i,k+x:len(RS)*rep_phases[j]+k+x:len(RS)]) \n",
    "            if (summ > max_worker_seq[k]):\n",
    "                N_Wrk_RC2_RS_adj2[i,k+x:len(RS)*rep_phases[j]+k+x:len(RS)] = np.round(N_Wrk_RC2_RS_adj[i,k+x:len(RS)*rep_phases[j]+k+x:len(RS)] * (max_worker_seq[k]/summ))\n",
    "        x = rep_phases[j]*7+x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#worker limit based on the total floor area defined in the REDi guidelines\n",
    "bld_area_ft2 = sum(fl_area)\n",
    "max_worker_tot1 = max(2.5*0.0001*bld_area_ft2 + 10, 20)\n",
    "max_worker_tot = min(max_worker_tot1, 260)\n",
    "\n",
    "N_Wrk_RC2_RS_adj3 = N_Wrk_RC2_RS_adj2\n",
    "\n",
    "for i in range(len(indx_repairable)):\n",
    "    y=0\n",
    "    for j in range(len(rep_phases)):\n",
    "        summ = sum(N_Wrk_RC2_RS_adj2[i,y:y+rep_phases[j]*7])\n",
    "        if (summ > max_worker_tot):\n",
    "            N_Wrk_RC2_RS_adj3[i,y:y+rep_phases[j]*7] = np.round(N_Wrk_RC2_RS_adj2[i,y:y+rep_phases[j]*7] * max_worker_tot/summ)\n",
    "        y = y+rep_phases[j]*7\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #elevator components adjustment to ensure the repair time is divided equally across stories \n",
    "# elev_array = np.maximum.reduce(N_Wrk_RC2_RS_adj3[:,5:-1:7].T)\n",
    "# n_wrk_elev = max(RC_table[RC_table[\"Repair Sequence\"]==6][\"Workers per damaged Qty\"])\n",
    "# elev_array = np.minimum(elev_array, np.ones((1,len(indx_repairable)))*n_elev*n_wrk_elev)\n",
    "# indx_elev_array = np.argmax(np.sum((N_Wrk_RC2_RS_adj3[:,5:-1:7]), axis=0))\n",
    "# N_Wrk_RC2_RS_adj3[:,5+7*indx_elev_array]=elev_array #修正电梯工人数\n",
    "# if len(np.nonzero(np.sum((N_Wrk_RC2_RS_adj3[:,5:-1:7]), axis=0)))>1:\n",
    "#     sys.exit(\"Elevator fragility should be assigned to one floor only\")\n",
    "# RT_RC2_RS_adj4 = np.divide(np.squeeze(RT_RC2_RS), N_Wrk_RC2_RS_adj3, out=np.zeros_like(np.squeeze(RT_RC2_RS)), where=N_Wrk_RC2_RS_adj3!=0) \n",
    "# RT_RC2_RS_days = RT_RC2_RS_adj4\n",
    "# RT_elev_adj = np.maximum.reduce(RT_RC2_RS_days[:,5:-1:7].T)/len(story) #find the max elevator repair time across stories\n",
    "# RT_RC2_RS_days[:,np.arange(5,len(RT_RC2_RS_days.T),7)] = np.tile(RT_elev_adj,(len(story),1)).T #平均分配到每个楼层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elevator components adjustment to ensure the repair time is divided equally across stories \n",
    "if len(np.squeeze(np.nonzero(np.sum((N_Wrk_RC2_RS_adj3[:,5:-1:7]), axis=0))))>1:  #补充np.squeeze\n",
    "    print(\"Elevator fragility assigned to more than one floor\")\n",
    "\n",
    "elev_story = [1, 30] #电梯所在楼层\n",
    "elev_story_max = (elev_story[1]-1)*7 #电梯分组 分割线\n",
    "\n",
    "# elev_array = np.maximum.reduce(N_Wrk_RC2_RS_adj3[:,5:-1:7].T) #沿着数组的指定轴，将数组的元素两两比较，逐步取最大值，最终返回一个包含这些最大值的数组。 5代表RS6; 不包括elev_story_max列\n",
    "elev_array1 = N_Wrk_RC2_RS_adj3[:,5+(elev_story[0]-1)*7]\n",
    "elev_array2 = N_Wrk_RC2_RS_adj3[:,5+(elev_story[1]-1)*7]\n",
    "n_wrk_elev = max(RC_table[RC_table[\"Repair Sequence\"]==6][\"Workers per damaged Qty\"])\n",
    "elev_array1 = np.minimum(elev_array1, np.ones((1,len(indx_repairable)))*n_elev[0]*n_wrk_elev)\n",
    "elev_array2 = np.minimum(elev_array2, np.ones((1,len(indx_repairable)))*n_elev[1]*n_wrk_elev)\n",
    "\n",
    "# indx_elev_array = np.argmax(np.sum((N_Wrk_RC2_RS_adj3[:,5:elev_story_max:7]), axis=0)) #argmax返回给定数组中最大值的索引\n",
    "N_Wrk_RC2_RS_adj3[:,5+(elev_story[0]-1)*7]=elev_array1 #修正电梯工人数\n",
    "N_Wrk_RC2_RS_adj3[:,5+(elev_story[1]-1)*7]=elev_array2 #修正电梯工人数\n",
    "\n",
    "RT_RC2_RS_adj4 = np.divide(np.squeeze(RT_RC2_RS), N_Wrk_RC2_RS_adj3, out=np.zeros_like(np.squeeze(RT_RC2_RS)), where=N_Wrk_RC2_RS_adj3!=0) #换算成天数\n",
    "RT_RC2_RS_days = RT_RC2_RS_adj4\n",
    "\n",
    "RT_elev_adj1 = RT_RC2_RS_days[:,5+(elev_story[0]-1)*7]/(elev_story[1]) #len(story) #find the max elevator repair time across stories\n",
    "RT_elev_adj2 = RT_RC2_RS_days[:,5+(elev_story[1]-1)*7]/(len(story)-elev_story[1]) #len(story) #find the max elevator repair time across stories\n",
    "\n",
    "RT_RC2_RS_days[:,np.arange(5,elev_story_max,7)] = np.tile(RT_elev_adj1,((elev_story[1]-1),1)).T #平均分配到每个楼层 #np.tile 用于将数组沿指定的维度进行重复\n",
    "RT_RC2_RS_days[:,np.arange(elev_story_max+5:len(RT_RC2_RS_days.T):7)] = np.tile(RT_elev_adj2,((len(story)-elev_story[1]+1),1)).T #平均分配到每个楼层 #np.tile 用于将数组沿指定的维度进行重复\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "RT_RC2_RS_days_mat=np.vstack((header_, (RT_RC2_RS_days)))\n",
    "pd.DataFrame(np.c_[col.T, RT_RC2_RS_days_mat]).to_csv(os.path.join(output_path,r'RT_RSeq_FR.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#需要保存的变量\n",
    "# 定义pickle文件的路径\n",
    "pickle_file_path = os.path.join(subdir_path, 'RT_results.pkl')\n",
    "\n",
    "output_dict = {\n",
    "    'RT_RC2_RS_days': RT_RC2_RS_days\n",
    "}\n",
    "\n",
    "# 保存数据到pickle文件\n",
    "with open(pickle_file_path, \"wb\") as file:\n",
    "    pickle.dump(output_dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pelicun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
